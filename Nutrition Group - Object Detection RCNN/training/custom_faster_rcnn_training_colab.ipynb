{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Training for Object Detection\n",
        "\n",
        "This training pipeline is based on https://github.com/sovit-123/fastercnn-pytorch-training-pipeline"
      ],
      "metadata": {
        "id": "3VCGSD6OHvmv"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4sjTjpNnhwoA"
      },
      "source": [
        "## Clone the Repository"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hqJgchTOh3Os"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/sovit-123/fastercnn-pytorch-training-pipeline.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZrgajbVrh6x9"
      },
      "outputs": [],
      "source": [
        "# Enter the repo directory.\n",
        "%cd fastercnn-pytorch-training-pipeline/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VTHv38whkGt_"
      },
      "outputs": [],
      "source": [
        "# Install the Requirements\n",
        "!pip install -r requirements.txt\n",
        "!pip install vision_transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install kaggle --upgrade"
      ],
      "metadata": {
        "id": "USulImhNx0rL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os, json, subprocess\n",
        "KAGGLE_CONFIG_DIR = \"/root/.kaggle\"\n",
        "\n",
        "def init_on_kaggle():\n",
        "    KAGGLE_CONFIG_DIR = os.path.join(os.path.expandvars('$HOME'), '.kaggle')\n",
        "    os.makedirs(KAGGLE_CONFIG_DIR, exist_ok = True)\n",
        "    api_dict = {\"username\":\"mlilyd\",\"key\":\"e8587ab3296805976d351236aa8a8857\"}\n",
        "    with open(f\"{KAGGLE_CONFIG_DIR}/kaggle.json\", \"w\", encoding='utf-8') as f:\n",
        "        json.dump(api_dict, f)\n",
        "    cmd = f\"chmod 600 {KAGGLE_CONFIG_DIR}/kaggle.json\"\n",
        "    output = subprocess.check_output(cmd.split(\" \"))\n",
        "    output = output.decode(encoding='UTF-8')\n",
        "    print(output)\n",
        "\n",
        "init_on_kaggle()"
      ],
      "metadata": {
        "id": "KtpilcSVzQPC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NLXEx7TTiOQ_"
      },
      "source": [
        "## Download the Dataset\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets list -s \"common vegetable object detection\""
      ],
      "metadata": {
        "id": "a5R08iIl1p9q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download \"slirq123/common-vegetable-dataset-for-object-detection\""
      ],
      "metadata": {
        "id": "mv6CLVv72UbL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip common-vegetable-dataset-for-object-detection.zip -d data/common-veggie\n",
        "!rm common-vegetable-dataset-for-object-detection.zip"
      ],
      "metadata": {
        "id": "gjfcrC7DD3o_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r2OW1Xj5ij96"
      },
      "source": [
        "## Create the Custom Dataset YAML File."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wc1raikijI5b"
      },
      "outputs": [],
      "source": [
        "%%writefile data_configs/common_veggie.yaml\n",
        "# Images and labels direcotry should be relative to train.py\n",
        "TRAIN_DIR_IMAGES: 'data/common-veggie/Train+xml/'\n",
        "TRAIN_DIR_LABELS: 'data/common-veggie/Train+xml/'\n",
        "VALID_DIR_IMAGES: 'data/common-veggie/Test+xml/'\n",
        "VALID_DIR_LABELS: 'data/common-veggie/Test+xml/'\n",
        "\n",
        "# Class names.\n",
        "CLASSES: [\n",
        "    '__background__',\n",
        "    'apple', 'banana', 'beetroot', 'bell pepper', 'cabbage', 'capsicum',\n",
        "    'carrot', 'cauliflower', 'chilli pepper', 'corn', 'cucumber', 'eggplant', 'eggs',\n",
        "    'garlic', 'ginger', 'grapes', 'jalapeno', 'kiwi', 'lemon', 'lettuce', 'mango',\n",
        "    'onion', 'orange', 'paprika', 'pear', 'peas', 'pineapple', 'pomengranate', 'potato', 'raddish',\n",
        "    'soy beans', 'spinach', 'sweetcorn', 'sweetpotato', 'tomato', 'turnip', 'watermelon',\n",
        "    'beans', 'cake', 'candy', 'cereal', 'chips', 'chocolate',\n",
        "    'coffee', 'fish', 'flour', 'honey', 'jam', 'juice', 'milk', 'nuts',\n",
        "    'oil', 'pasta', 'rice', 'soda', 'spices', 'sugar', 'tea', 'tomato_sauce',\n",
        "    'vinegar', 'water', 'sausage', 'bread', 'food_bread', 'butter'\n",
        "]\n",
        "\n",
        "# Number of classes (object classes + 1 for background class in Faster RCNN).\n",
        "NC: 66\n",
        "\n",
        "# Whether to save the predictions of the validation set while training.\n",
        "SAVE_VALID_PREDICTION_IMAGES: True"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile data_configs/bread.yaml\n",
        "# Images and labels direcotry should be relative to train.py\n",
        "TRAIN_DIR_IMAGES: 'data/bread/Train+xml/'\n",
        "TRAIN_DIR_LABELS: 'data/bread/Train+xml/'\n",
        "VALID_DIR_IMAGES: 'data/bread/Test+xml/'\n",
        "VALID_DIR_LABELS: 'data/bread/Test+xml/'\n",
        "\n",
        "# Class names.\n",
        "CLASSES: [\n",
        "    '__background__',\n",
        "    'apple', 'banana', 'beetroot', 'bell pepper', 'cabbage', 'capsicum',\n",
        "    'carrot', 'cauliflower', 'chilli pepper', 'corn', 'cucumber', 'eggplant', 'eggs',\n",
        "    'garlic', 'ginger', 'grapes', 'jalapeno', 'kiwi', 'lemon', 'lettuce', 'mango',\n",
        "    'onion', 'orange', 'paprika', 'pear', 'peas', 'pineapple', 'pomengranate', 'potato', 'raddish',\n",
        "    'soy beans', 'spinach', 'sweetcorn', 'sweetpotato', 'tomato', 'turnip', 'watermelon',\n",
        "    'beans', 'cake', 'candy', 'cereal', 'chips', 'chocolate',\n",
        "    'coffee', 'fish', 'flour', 'honey', 'jam', 'juice', 'milk', 'nuts',\n",
        "    'oil', 'pasta', 'rice', 'soda', 'spices', 'sugar', 'tea', 'tomato_sauce',\n",
        "    'vinegar', 'water', 'sausage', 'bread', 'food_bread', 'butter'\n",
        "]\n",
        "\n",
        "# Number of classes (object classes + 1 for background class in Faster RCNN).\n",
        "NC: 66\n",
        "\n",
        "# Whether to save the predictions of the validation set while training.\n",
        "SAVE_VALID_PREDICTION_IMAGES: True"
      ],
      "metadata": {
        "id": "b1ffnbd2IB6p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile data_configs/sausage.yaml\n",
        "# Images and labels direcotry should be relative to train.py\n",
        "TRAIN_DIR_IMAGES: 'data/sausage/Train+xml/'\n",
        "TRAIN_DIR_LABELS: 'data/sausage/Train+xml/'\n",
        "VALID_DIR_IMAGES: 'data/sausage/Test+xml/'\n",
        "VALID_DIR_LABELS: 'data/sausage/Test+xml/'\n",
        "\n",
        "# Class names.\n",
        "CLASSES: [\n",
        "    '__background__',\n",
        "    'apple', 'banana', 'beetroot', 'bell pepper', 'cabbage', 'capsicum',\n",
        "    'carrot', 'cauliflower', 'chilli pepper', 'corn', 'cucumber', 'eggplant', 'eggs',\n",
        "    'garlic', 'ginger', 'grapes', 'jalapeno', 'kiwi', 'lemon', 'lettuce', 'mango',\n",
        "    'onion', 'orange', 'paprika', 'pear', 'peas', 'pineapple', 'pomengranate', 'potato', 'raddish',\n",
        "    'soy beans', 'spinach', 'sweetcorn', 'sweetpotato', 'tomato', 'turnip', 'watermelon',\n",
        "    'beans', 'cake', 'candy', 'cereal', 'chips', 'chocolate',\n",
        "    'coffee', 'fish', 'flour', 'honey', 'jam', 'juice', 'milk', 'nuts',\n",
        "    'oil', 'pasta', 'rice', 'soda', 'spices', 'sugar', 'tea', 'tomato_sauce',\n",
        "    'vinegar', 'water', 'sausage', 'bread', 'food_bread', 'butter'\n",
        "]\n",
        "\n",
        "# Number of classes (object classes + 1 for background class in Faster RCNN).\n",
        "NC: 66\n",
        "\n",
        "# Whether to save the predictions of the validation set while training.\n",
        "SAVE_VALID_PREDICTION_IMAGES: True"
      ],
      "metadata": {
        "id": "kqrPE6AlIJHH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-4iJEC0zjzE5"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3juf3R0BzE-w"
      },
      "outputs": [],
      "source": [
        "!wandb disabled\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python train.py --config data_configs/bread.yaml --epochs 50 --model fasterrcnn_resnet50_fpn_v2 --project-name custom_training --batch-size 2 --no-mosaic"
      ],
      "metadata": {
        "id": "7kHKGJjta2pM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python train.py --config data_configs/sausage.yaml --epochs 50 --model fasterrcnn_resnet50_fpn_v2 --project-name custom_training --batch-size 2 --no-mosaic"
      ],
      "metadata": {
        "id": "Q70kx775IU5N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python train.py --config data_configs/common_veggie.yaml --epochs 50 --model fasterrcnn_resnet50_fpn_v2 --project-name custom_training --batch-size 2 --no-mosaic"
      ],
      "metadata": {
        "id": "vYS4fv2BIVTx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i0RP6pmDkB8Y"
      },
      "source": [
        "## Visualize Validation Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5MLvgLUbJudR"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import glob as glob"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_VwkIcbzJxDF"
      },
      "outputs": [],
      "source": [
        "results_dir_path = '/content/fastercnn-pytorch-training-pipeline/outputs/training/nutrition'\n",
        "valid_images = glob.glob(f\"{results_dir_path}/*.jpg\")\n",
        "\n",
        "for i in range(2):\n",
        "    plt.figure(figsize=(10, 7))\n",
        "    image = plt.imread(valid_images[i])\n",
        "    plt.imshow(image)\n",
        "    plt.axis('off')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Pk7SHEaLJha"
      },
      "source": [
        "## Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AsfiPcc94glV"
      },
      "outputs": [],
      "source": [
        "# No verbose mAP.\n",
        "!python eval.py --weights outputs/training/nutrition/best_model.pth --config data_configs/fruits.yaml --model fasterrcnn_resnet50_fpn_v2"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}